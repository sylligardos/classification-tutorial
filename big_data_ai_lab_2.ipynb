{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI & Big Data - Time series - Lab. 2 - Classification\n",
        "\n",
        "This lab consists of six parts, each building upon the previous one, gradually increasing in complexity.\n",
        "\n",
        "Deliverables:\n",
        "- A .ipynb file containing your solutions.\n",
        "- A PDF export of the notebook, ensuring that all cells have been executed.\n",
        "\n",
        "For every question, please provide **short** but **informative** answers.\n",
        "\n",
        "⚠️ Important: While you are free to use external resources, please don't rely blindly on ChatGPT - I'll find out!\n",
        "\n",
        "Let's go!"
      ],
      "metadata": {
        "id": "1HHMi17Fcni8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup environment and download datasets"
      ],
      "metadata": {
        "id": "hGH3fQKUdSjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aeon\n",
        "!pip install seaborn\n",
        "!pip install dtw-python\n",
        "!pip install tqdm\n",
        "!pip install fastdtw\n",
        "!pip install pycatch22"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R3s7jKVCdhoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from aeon.datasets import load_arrow_head, load_basic_motions\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import time\n",
        "import fastdtw\n",
        "\n",
        "x_train_full, y_train = load_arrow_head(split='train')\n",
        "x_test_full, y_test = load_arrow_head(split='test')\n",
        "print(f\"Arrow Head dataset of type {type(x_train_full)} and shapes, x_train: {x_train_full.shape}, y_train: {y_train.shape}, x_test: {x_test_full.shape}, y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "dLQ_RbmjdQ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train_full[:, 0], x_test_full[:, 0]"
      ],
      "metadata": {
        "id": "fCjPmn4p1uTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "id": "hYLPXkCzgvjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "1. What are the dimensions of the downloaded datasets? Write their meaning and value for every subset.\n",
        "2. What is the format of the labels? How many classes do we have?\n",
        "3. Look into the documentation of the aeon library and write below the meaning of each class.\n",
        "\n",
        "**Answers:**"
      ],
      "metadata": {
        "id": "0JpOL6cofDGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Visualizing and Understanding the Data\n",
        "\n",
        "- Create a subplot with 3 rows and 2 columns.\n",
        "- Each row should correspond to a different class in the dataset.\n",
        "- Each column should distinguish between different subsets (e.g., training vs. test sets, different conditions, etc.).\n",
        "- Plot all samples within each class to observe variations and patterns.\n",
        "\n",
        "This visualization will help in understanding the structure of the dataset and how different classes are distributed."
      ],
      "metadata": {
        "id": "Jqgrk279fmNS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81sLyhApbpsc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3, 2, figsize=(10, 5))\n",
        "\n",
        "# TODO\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. What do you observe? Describe the differences between the classes based on their visual patterns.\n",
        "2. Do you understand the classification task? If you were the classifier, what key characteristics would you focus on to distinguish between classes?\n",
        "3. Do you notice any samples that could be problematic? If so, explain why they might be challenging for classification (e.g., overlap between classes, noise, outliers).\n",
        "\n",
        "**Answers:**"
      ],
      "metadata": {
        "id": "dIQIP7yGjjic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Distance-based classifiers"
      ],
      "metadata": {
        "id": "ehks2KQ7kAiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.1: Implement the Euclidean and the DTW distances"
      ],
      "metadata": {
        "id": "Zyf8nSCXkJi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(a, b):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "print(f\"Euclidian distance value: {euclidean_distance(x_train[0], x_train[1])}\")"
      ],
      "metadata": {
        "id": "6ZAK_b_Pji2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dtw(a, b, window=100):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "distance_matrix = dtw(x_train[0], x_train[1], window=1)\n",
        "print(f\"DTW distance value: {distance_matrix[-1, -1]}\")"
      ],
      "metadata": {
        "id": "stHDp6DurkWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_cost_path(matrix):\n",
        "  i, j = matrix.shape[0] - 1, matrix.shape[1] - 1\n",
        "  path = [(i, j)]\n",
        "\n",
        "  while i > 0 or j > 0:\n",
        "      neighbors = []\n",
        "      if i > 0:\n",
        "          neighbors.append((matrix[i-1, j], i-1, j))\n",
        "      if j > 0:\n",
        "          neighbors.append((matrix[i, j-1], i, j-1))\n",
        "      if i > 0 and j > 0:\n",
        "          neighbors.append((matrix[i-1, j-1], i-1, j-1))\n",
        "\n",
        "      _, i, j = min(neighbors)\n",
        "      path.append((i, j))\n",
        "\n",
        "  return path[::-1]\n",
        "\n",
        "def visualize_distance_matrix(matrix):\n",
        "  path = min_cost_path(matrix)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(8, 6))\n",
        "  # TODO\n",
        "\n",
        "  path_x, path_y = zip(*path)\n",
        "  ax.plot(np.array(path_y) + 0.5, np.array(path_x) + 0.5, marker=\"o\", color=\"red\", markersize=2)\n",
        "\n",
        "  ax.invert_yaxis()\n",
        "  plt.title(\"DTW Distance Matrix with Path\")\n",
        "  plt.show()\n",
        "\n",
        "visualize_distance_matrix(distance_matrix)"
      ],
      "metadata": {
        "id": "e01DSgztcwmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dtw_distance(a, b):\n",
        "  # TODOD: Wrapper that returns the final distance\n",
        "\n",
        "def my_fastdtw(a, b):\n",
        "    return fastdtw.fastdtw(a, b, radius=20)[0]"
      ],
      "metadata": {
        "id": "lm5wxRN4Gf_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a random example between two time series and answer the questions below.\n",
        "\n",
        "**Questions:**\n",
        "1. Does your implementation match the Euclidean distance when window = 1 ? Why or why not?\n",
        "2. What do you observe as you change the window size? How does it affect the DTW alignment?\n",
        "3. Up to which value does the window size affect the result? Justify your answer.\n",
        "\n",
        "**Answers:**"
      ],
      "metadata": {
        "id": "5eq0h0ZLwTeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.2: Implement the kNN classifier"
      ],
      "metadata": {
        "id": "BVZDwbeEvGtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier_single(x_train, y_train, x_test, distance_function, k=5):\n",
        "  # TODO\n",
        "  # Compute the distance of the test value to every train\n",
        "  distances =\n",
        "\n",
        "  # Find the k min distances\n",
        "  nearest_neighbors =\n",
        "\n",
        "  # Return their voted most label\n",
        "  votes =\n",
        "  labels, counts =\n",
        "  prediction =\n",
        "\n",
        "  return prediction\n",
        "\n",
        "ed_tic = time.time()\n",
        "knn_classifier_single(x_train, y_train, x_test[0], euclidean_distance, k=5)\n",
        "ed_toc = time.time()\n",
        "\n",
        "dtw_tic = time.time()\n",
        "knn_classifier_single(x_train, y_train, x_test[0], dtw_distance, k=5)\n",
        "dtw_toc = time.time()\n",
        "\n",
        "fast_dtw_tic = time.time()\n",
        "knn_classifier_single(x_train, y_train, x_test[0], my_fastdtw, k=5)\n",
        "fast_dtw_toc = time.time()\n",
        "\n",
        "print(f\"ED distance time: {(ed_toc - ed_tic):.4f} secs\")\n",
        "print(f\"DTW distance time: {(dtw_toc - dtw_tic):.4f} secs\")\n",
        "print(f\"Fast DTW distance time: {(fast_dtw_toc - fast_dtw_tic):.4f} secs\")"
      ],
      "metadata": {
        "id": "hkG71BoXvK7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier(x_train, y_train, x_test, distance_function, k=5):\n",
        "  predictions = []\n",
        "  # TODO: Implement a wrapper for multiple predictions\n",
        "\n",
        "  return predictions\n",
        "\n",
        "preds = knn_classifier(x_train, y_train, x_test, euclidean_distance, k=22)"
      ],
      "metadata": {
        "id": "nSa905640J2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(a, b):\n",
        "  # TODO\n",
        "\n",
        "print(accuracy(preds, y_test))"
      ],
      "metadata": {
        "id": "a0WcIqLT0ncI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ed_trials = []\n",
        "for k in tqdm(range(1, 20)):\n",
        "  # TODO: Test for multiple k and save results in list of dictionaries"
      ],
      "metadata": {
        "id": "s5eQzsL60dmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds = knn_classifier(x_train, y_train, x_test, my_fastdtw, 7)\n",
        "\n",
        "dtw_trials = []\n",
        "for k in tqdm(range(1, 20, 2)):\n",
        "  # TODO: Use best k from above and test for multiple windows\n",
        "  # TODO: Save results in list of dictionaries"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VR3gLscy1Ssp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ed_trials_df = pd.DataFrame(ed_trials)\n",
        "dtw_trials_df = pd.DataFrame(dtw_trials)\n",
        "\n",
        "# TODO: Visualize acc for different k and different window sizes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WurjgMJL1HCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "1. What is the best value for k and the window size? How do they impact the classification performance?\n",
        "\n",
        "2. Which distance measure should we use? Justify your choice based on the dataset and DTW behavior.\n",
        "\n",
        "3. What do you think about the results?"
      ],
      "metadata": {
        "id": "YzmK1CPyJhPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Feature-based classifiers"
      ],
      "metadata": {
        "id": "kLCwkFJ2J55U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4.1: Feature extraction\n",
        "\n",
        "1. Extract features from the time series data using the Catch22 library. Ensure that each sample is transformed into a feature vector.\n",
        "2. Convert the extracted features from NumPy arrays to Torch tensors, preparing them for use in a PyTorch model. Don't forget the labels too."
      ],
      "metadata": {
        "id": "kA98tVrtKynm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycatch22\n",
        "\n",
        "X_train, Y_train =\n",
        "X_test, Y_test ="
      ],
      "metadata": {
        "id": "bcNwVobJJCX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4.2: Setup the training pipeline with Torch\n",
        "\n",
        "1. Define a simple linear model using PyTorch's nn.Linear. Ensure it takes the extracted feature vectors as input and outputs class probabilities.\n",
        "2. Choose a loss function and an optimizer, such as Cross-Entropy Loss and Adam/SGD.\n",
        "3. Implement the training loop, including forward pass, loss computation, backpropagation, and parameter updates. Train the model for a reasonable number of epochs.\n",
        "4. Evaluate the model on the test set and report relevant metrics (e.g., accuracy, precision, recall)."
      ],
      "metadata": {
        "id": "Mp3W1CL1MjuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # TODO\n",
        ")"
      ],
      "metadata": {
        "id": "yA0pkh0TMoi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn =\n",
        "optimizer ="
      ],
      "metadata": {
        "id": "GejUVDbLNWWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "batch_size = 16\n",
        "dataset_size = Y_train.shape[0]\n",
        "\n",
        "history = []\n",
        "pbar = tqdm(range(num_epochs), desc='Training', leave=True)\n",
        "for n in pbar:\n",
        "  curr_indexes =\n",
        "  curr_x =\n",
        "  curr_y =\n",
        "  # TODO: Complete the training loop\n",
        "\n",
        "  acc =\n",
        "  history.append({'epoch': n, 'loss': , 'accuracy': })\n",
        "  pbar.set_description(f\"Training loss {loss}, Training accuracy: {acc}\")\n",
        "  pbar.refresh()"
      ],
      "metadata": {
        "id": "taMRPCDYN1hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the accuracy on the test set\n",
        "print(f\"MLPs accuracy: {}\")"
      ],
      "metadata": {
        "id": "pNHyT8QGO5ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(history)\n",
        "\n",
        "# TODO: Plot the training loss and accuracy per epoch\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RHydwwxxR2tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "1. Experiment with different hyperparameters (n_layers, neurons per layer, activation functions, n_epochs, batch_size, etc.). What is the best combination of hyperparameters you found? Justify your choice.\n",
        "2. Compare the results of the feature-based approach with the previous approach. Are the results better? Why do you think this is the case, considering the data?"
      ],
      "metadata": {
        "id": "qMoC1cLIUYpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Raw-based classifiers\n",
        "\n",
        "In this section, we will train a classifier directly on the raw time series data.\n",
        "1. Prepare the dataset in its raw form (without feature extraction).\n",
        "2. Define a small 1D Convolutional Neural Network (1D-CNN) architecture for classification.\n",
        "3. Implement the training pipeline, including:\n",
        "  * Loss function and optimizer selection\n",
        "  * Training loop\n",
        "  * Model evaluation"
      ],
      "metadata": {
        "id": "QU_UA5GyVKU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    # TODO\n",
        ")"
      ],
      "metadata": {
        "id": "mZRnIundTkKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train =\n",
        "X_test, Y_test ="
      ],
      "metadata": {
        "id": "O51IvcsbYnww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn =\n",
        "optimizer =\n",
        "\n",
        "num_epochs =\n",
        "batch_size =\n",
        "dataset_size = Y_train.shape[0]\n",
        "\n",
        "cnn_history = []\n",
        "pbar = tqdm(range(num_epochs), desc='Training', leave=True)\n",
        "for n in pbar:\n",
        "  # TODO\n",
        "\n",
        "  pbar.set_description(f\"Training loss {loss}, Training accuracy: {acc}\")\n",
        "  pbar.refresh()"
      ],
      "metadata": {
        "id": "Qo2y2TLIYvdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "print(f\"CNNs accuracy: {}\")"
      ],
      "metadata": {
        "id": "QwZGiPdhZ7vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(cnn_history)\n",
        "\n",
        "# TODO: Produce the same plots as before\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NT0an__NbJOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "1.  Are the results now better than before? If so, why do you think that is?\n",
        "2. Adjust the hyper-parameters (e.g., number of filters, kernel size, learning rate, batch size, etc.) as you did before. What do you think are the best hyper-parameter settings based on your experiments? Justify your answer by presenting the results and explaining the reasoning behind your choices.\n",
        "\n",
        "**Answers:**"
      ],
      "metadata": {
        "id": "W1L71tIlcJnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Discussion\n",
        "\n",
        "This part of the exercise focuses on discussing your results and demonstrating your understanding of the methods and concepts. Please answer the following questions in at most two short paragraphs.\n",
        "\n",
        "**Questions:**\n",
        "- Which method did you like the most, and why?\n",
        "- Based on your experience, which distance measure do you think works best for this task?\n",
        "- What did you find challenging to understand, and what concepts did you find straightforward?\n",
        "- What are the pros and cons of each method you tried?\n",
        "\n",
        "There are no strictly \"correct\" answers, but your grade will be based on how well you understand and articulate the concepts. Reflect on what you've done, and make sure to explain your reasoning clearly."
      ],
      "metadata": {
        "id": "AjlWkJqocZ2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**"
      ],
      "metadata": {
        "id": "tXjNH8DJcfXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The End!**"
      ],
      "metadata": {
        "id": "qfHYU4RGdPHq"
      }
    }
  ]
}